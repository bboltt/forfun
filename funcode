import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
from pyspark.sql import functions as F

# --- Custom Imports ---
from optimal_spark_config.create_spark_instance import generate_spark_instance

# ================= CONFIGURATION =================
RUN_ON_FULL_DATA = True 

# Paths & Tables
HIVE_TABLE = 'dm_fraud_detection.cs_training_data_v2'
LOCAL_FILENAME = 'eda_dataframe_1.csv'
DATA_FOLDER = 'development_work/customer_score_v2/eda_data/'
SAVE_FOLDER = 'development_work/customer_score_v2/misc_figures/'

# Columns
DATE_COL = 'applicationdate'
FRAUD_COL = 'fraud_label_180'
BOOKED_COL = 'booked'

def download_sample_if_needed(spark):
    full_path = os.path.join(DATA_FOLDER, LOCAL_FILENAME)
    if not os.path.exists(full_path):
        print(f"Local file not found. Sampling 1% from {HIVE_TABLE}...")
        os.makedirs(DATA_FOLDER, exist_ok=True)
        spark.table(HIVE_TABLE).sample(0.01).toPandas().to_csv(full_path, index=False)
    return full_path

def get_dataframe(spark):
    if RUN_ON_FULL_DATA:
        print(f"--- MODE: FULL DATA (Hive: {HIVE_TABLE}) ---")
        df = spark.table(HIVE_TABLE)
    else:
        print(f"--- MODE: LOCAL SAMPLE ({LOCAL_FILENAME}) ---")
        csv_path = download_sample_if_needed(spark)
        df = spark.read.option("header", "true").option("inferSchema", "true").csv(csv_path)

    # Preprocessing
    df = df.withColumn(DATE_COL, F.to_date(F.col(DATE_COL)))
    df = df.fillna({FRAUD_COL: 0})
    return df

def save_and_print(df, name):
    """Helper to print DF and save to CSV"""
    print(f"\n--- DATA: {name} ---")
    print(df)
    print("-" * 30)
    csv_path = os.path.join(SAVE_FOLDER, f'{name}.csv')
    df.to_csv(csv_path, index=False)
    print(f"Saved data to: {csv_path}\n")

def plot_monthly_stats(df):
    print("--- Calculating Monthly Statistics ---")
    
    # 1. Create Month Column and Aggregate in Spark
    df_monthly = df.withColumn('month_start', F.trunc(F.col(DATE_COL), 'Month'))
    
    stats_spark = df_monthly.groupBy('month_start').agg(
        F.count('*').alias('total_apps'),
        F.sum(BOOKED_COL).alias('total_booked'),
        F.sum(FRAUD_COL).alias('total_fraud')
    )
    
    # Calculate Rates
    stats_spark = stats_spark.withColumn('booked_rate', F.col('total_booked') / F.col('total_apps'))
    stats_spark = stats_spark.withColumn('fraud_rate', F.col('total_fraud') / F.col('total_apps'))
    
    # Collect to Pandas
    pdf = stats_spark.orderBy('month_start').toPandas()
    
    # --- EXPORT DATA ---
    os.makedirs(SAVE_FOLDER, exist_ok=True)
    save_and_print(pdf, 'monthly_high_level_stats')

    # --- PLOTTING ---
    # Plot 1: Volume
    plt.figure(figsize=(12, 6))
    sns.barplot(data=pdf, x='month_start', y='total_apps', color='lightgray', label='Total Apps')
    sns.barplot(data=pdf, x='month_start', y='total_booked', color='navy', label='Booked Apps')
    plt.xticks(rotation=45)
    plt.title("Monthly Volume")
    plt.legend()
    plt.tight_layout()
    plt.savefig(SAVE_FOLDER + 'monthly_volume.jpg')
    plt.clf()

    # Plot 2: Rates (FIXED LEGEND)
    fig, ax1 = plt.subplots(figsize=(12, 6))
    
    # Axis 1: Booked Rate (Blue)
    sns.lineplot(data=pdf, x='month_start', y='booked_rate', ax=ax1, color='blue', marker='o', label='Booked Rate')
    ax1.set_ylabel('Booked Rate', color='blue')
    ax1.set_ylim(0, None) 
    
    # Axis 2: Fraud Rate (Red)
    ax2 = ax1.twinx()
    sns.lineplot(data=pdf, x='month_start', y='fraud_rate', ax=ax2, color='red', marker='o', label='Fraud Rate')
    ax2.set_ylabel('Fraud Rate', color='red')
    ax2.set_ylim(0, None)

    # --- LEGEND FIX ---
    # Gather handles and labels from BOTH axes
    lines_1, labels_1 = ax1.get_legend_handles_labels()
    lines_2, labels_2 = ax2.get_legend_handles_labels()
    
    # Create a single legend box above the plot
    ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='upper center', bbox_to_anchor=(0.5, 1.15), ncol=2)

    plt.title("Monthly Trends: Booked Rate vs Fraud Rate", y=1.15) # Move title up slightly
    plt.tight_layout() # Adjust layout so the legend isn't cut off
    plt.savefig(SAVE_FOLDER + 'monthly_rates.jpg')
    plt.clf()

def plot_distributions(df):
    print("--- Generating Distribution Plots & Stats ---")
    
    # 1. Sample for Visualization/Stats
    if RUN_ON_FULL_DATA:
        print("Sampling 10% of full data for detailed analysis...")
        pdf = df.sample(fraction=0.1).toPandas()
    else:
        pdf = df.toPandas()

    # 2. Feature Engineering
    pdf['relat_age_bin'] = pd.cut(
        pdf['max_open_age'],
        bins=[0, 0.5, 1, 2, 999],
        labels=['new_custs_<6mo', 'newish_6mo_1y', 'somewhat_new_1y_2y', 'established_>2y']
    )

    # --- EXPORT DATA: Relationship Age Stats ---
    rel_stats = pdf.groupby('relat_age_bin', observed=True).agg(
        count=(FRAUD_COL, 'size'),
        fraud_count=(FRAUD_COL, 'sum'),
        fraud_rate=(FRAUD_COL, 'mean')
    ).reset_index()
    save_and_print(rel_stats, 'relationship_age_fraud_stats')

    # --- PLOTTING ---
    # Barplot
    sns.barplot(data=pdf, x='relat_age_bin', y=FRAUD_COL, errorbar=("ci", 95))
    plt.savefig(SAVE_FOLDER + 'fraud_dist_by_relationship_length.jpg')
    plt.clf()

    # Scatter (Sample further if needed)
    scatter_subset = pdf.sample(n=min(50000, len(pdf))) 
    sns.scatterplot(data=scatter_subset, x='max_open_age', y='total_accts', size=0.5, alpha=0.3, hue=FRAUD_COL)
    plt.savefig(SAVE_FOLDER + 'total_accts_vs_relationship.jpg')
    plt.clf()

    # Histograms & App Counts
    app_cols = [c for c in pdf.columns if c.startswith("total_apps_in_last_")]
    windows = sorted(list(set([int(re.search(r'(\d+)', c).group(1)) for c in app_cols if re.search(r'(\d+)', c)])))

    if windows:
        app_stats_list = []

        fig, ax = plt.subplots(nrows=len(windows), ncols=1, figsize=(8, 3 * len(windows)))
        if len(windows) == 1: ax = [ax]

        for i, w in enumerate(windows):
            # Find columns dynamically
            possible_app = [c for c in pdf.columns if f"last_{w}" in c and "booked" not in c]
            if possible_app:
                app_col = possible_app[0]
                
                # Calculate Stats
                avg_apps = pdf[app_col].mean()
                max_apps = pdf[app_col].max()
                zeros = (pdf[app_col] == 0).sum()
                app_stats_list.append({'window': f'{w}_days', 'avg_apps': avg_apps, 'max_apps': max_apps, 'zero_count': zeros})

                # Plot
                subset = pdf[pdf[app_col] > 0]
                sns.histplot(data=subset, x=app_col, bins=range(0, 30), alpha=0.5, ax=ax[i], color="blue", label="All Apps")
                
                ax[i].set_title(f"{w}-day window")
                ax[i].legend()
        
        plt.tight_layout()
        plt.savefig(SAVE_FOLDER + 'apps_per_social.jpg')
        plt.clf()
        
        # Save App Stats
        save_and_print(pd.DataFrame(app_stats_list), 'application_volume_stats')

def analyze():
    spark = generate_spark_instance(
        total_memory=100,
        total_vcpu=50,
        python37=True,
        appName='originations_customer_score_eda'
    )

    df = get_dataframe(spark)
    plot_monthly_stats(df)
    plot_distributions(df)
    print("\nEDA Complete. All figures and CSVs saved.")

if __name__ == "__main__":
    analyze()
